{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978b9225",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Missing key: confidence",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 375\u001b[39m\n\u001b[32m    373\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mipykernel_launcher\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m sys.argv[\u001b[32m0\u001b[39m]:\n\u001b[32m    374\u001b[39m     sys.argv = [sys.argv[\u001b[32m0\u001b[39m], \u001b[33m\"\u001b[39m\u001b[33m--input\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m../data/processed/template.csv\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m--model\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mgpt-4o\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m--> \u001b[39m\u001b[32m375\u001b[39m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 367\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    364\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnknown Type \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mp\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m. Must be one of: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mCANONICAL_TYPES\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    365\u001b[39m         target_types.append(n)\n\u001b[32m--> \u001b[39m\u001b[32m367\u001b[39m \u001b[43mlabel_merged\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_types\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    368\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m[OK] All done. Merged output at: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mOUT_PATH\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 312\u001b[39m, in \u001b[36mlabel_merged\u001b[39m\u001b[34m(df, target_types, model)\u001b[39m\n\u001b[32m    309\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m    311\u001b[39m prompt = build_user_prompt(type_name, text)\n\u001b[32m--> \u001b[39m\u001b[32m312\u001b[39m result = \u001b[43mcall_openai\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mSYSTEM_PROMPT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallowed_predicates\u001b[49m\u001b[43m=\u001b[49m\u001b[43mallowed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    314\u001b[39m pred = result.get(\u001b[33m\"\u001b[39m\u001b[33mpredicate\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    315\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m pred \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m allowed:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 270\u001b[39m, in \u001b[36mcall_openai\u001b[39m\u001b[34m(model, system_prompt, user_prompt, allowed_predicates)\u001b[39m\n\u001b[32m    268\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m\"\u001b[39m\u001b[33mpredicate\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mconfidence\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mrationale\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m    269\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m data:\n\u001b[32m--> \u001b[39m\u001b[32m270\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMissing key: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    272\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m data.get(\u001b[33m\"\u001b[39m\u001b[33mpredicate\u001b[39m\u001b[33m\"\u001b[39m) == \u001b[33m\"\u001b[39m\u001b[33mPressured Seliing\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    273\u001b[39m     data[\u001b[33m\"\u001b[39m\u001b[33mpredicate\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[33m\"\u001b[39m\u001b[33mPressured Selling\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mValueError\u001b[39m: Missing key: confidence"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Dark Pattern predicate labeling (single MERGED output; no intermediate split files).\n",
    "\n",
    "- Reads:   data/processed/template.csv           (default; change with --input)\n",
    "- Writes:  data/processed/merged_output.csv      (single merged file)\n",
    "- Uses:    OPENAI_API_KEY from .env (python-dotenv)\n",
    "\n",
    "Usage:\n",
    "  pip install openai>=1.0.0 python-dotenv pandas\n",
    "  python merged_labeler.py --model gpt-4.1-mini\n",
    "  # 특정 타입만\n",
    "  python merged_labeler.py --types \"Urgency,Scarcity\"\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import time\n",
    "import argparse\n",
    "from typing import Dict, List, Any\n",
    "\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# --- Load .env so OPENAI_API_KEY is available to OpenAI() ---\n",
    "load_dotenv()\n",
    "\n",
    "# ---------------- Config ----------------\n",
    "DEFAULT_INPUT = os.path.join(\"data\", \"processed\", \"template.csv\")\n",
    "DEFAULT_MODEL = \"gpt-4o\"\n",
    "OUT_PATH     = os.path.join(\"data\", \"processed\", \"merged_output.csv\")  # 단일 병합 파일\n",
    "\n",
    "CANONICAL_TYPES = [\n",
    "    \"Urgency\",\n",
    "    \"Misdirection\",\n",
    "    \"Social Proof\",\n",
    "    \"Scarcity\",\n",
    "    \"Not Dark Pattern\",\n",
    "]\n",
    "\n",
    "# Map common typos/variants to canonical\n",
    "TYPE_NORMALIZE = {\n",
    "    \"urgency\": \"Urgency\",\n",
    "    \"misdirection\": \"Misdirection\",\n",
    "    \"social proof\": \"Social Proof\",\n",
    "    \"social_proof\": \"Social Proof\",\n",
    "    \"scarcity\": \"Scarcity\",\n",
    "    \"not dark pattern\": \"Not Dark Pattern\",\n",
    "    \"not_dark_pattern\": \"Not Dark Pattern\",\n",
    "    \"not darkpattern\": \"Not Dark Pattern\",\n",
    "    \"notdarkpattern\": \"Not Dark Pattern\",\n",
    "    \"no dark pattern\": \"Not Dark Pattern\",\n",
    "    \"none\": \"Not Dark Pattern\",\n",
    "}\n",
    "\n",
    "# Allowed predicates per Type (exact strings)\n",
    "PREDICATES: Dict[str, List[str]] = {\n",
    "    \"Urgency\": [\n",
    "        \"Countdown Timers\",\n",
    "        \"Limited-time Messages\",\n",
    "    ],\n",
    "    \"Misdirection\": [\n",
    "        \"Confirmshaming\",\n",
    "        \"Trick Questions\",\n",
    "        \"Pressured Selling\",\n",
    "    ],\n",
    "    \"Social Proof\": [\n",
    "        \"Activity Notifications\",\n",
    "        \"Testimonials of Uncertain Origin\",\n",
    "    ],\n",
    "    \"Scarcity\": [\n",
    "        \"Low-stock Messages\",\n",
    "        \"High-demand Messages\",\n",
    "    ],\n",
    "    \"Not Dark Pattern\": [\n",
    "        \"None\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Detailed definitions (from your spec)\n",
    "DEFINITIONS = {\n",
    "    \"Urgency\": {\n",
    "        \"Definition\": (\"When a user is placed under time pressure, they are less able to critically \"\n",
    "                       \"evaluate the information shown to them because they have less time and may \"\n",
    "                       \"experience anxiety or stress. Providers can use this to their advantage, to push \"\n",
    "                       \"them into completing an action that may not entirely be in the user's interest.\"),\n",
    "        \"Predicates\": {\n",
    "            \"Countdown Timers\": \"Indicating to users that a deal or discount will expire using a counting-down timer\",\n",
    "            \"Limited-time Messages\": \"Indicating to users that a deal or sale will expire will expire soon without specifying a deadline\",\n",
    "        },\n",
    "    },\n",
    "    \"Misdirection\": {\n",
    "        \"Predicates\": {\n",
    "            \"Confirmshaming\": \"Using language and emotion (shame) to steer users away from making a certain choice\",\n",
    "            \"Trick Questions\": \"Using confusing language to steer users into making certain choices\",\n",
    "            \"Pressured Selling\": \"Pre-selecting more expensive variations of a product, or pressuring the user to accept the more expensive variations of a product and related products\",\n",
    "        },\n",
    "    },\n",
    "    \"Social Proof\": {\n",
    "        \"Definition\": (\"Social Proof is a dark pattern that leverages social cues to influence user behavior. \"\n",
    "                       \"It creates the perception that other people are already taking an action, which pressures \"\n",
    "                       \"users to conform. This can distort independent decision-making by making choices appear \"\n",
    "                       \"more common or trustworthy than they actually are.\"),\n",
    "        \"Predicates\": {\n",
    "            \"Activity Notifications\": (\"Shows real-time or simulated notifications about other users’ activities \"\n",
    "                                       \"(e.g., “5 people just purchased this item”). These cues are often exaggerated \"\n",
    "                                       \"or fabricated to pressure users into taking quick action.\"),\n",
    "            \"Testimonials of Uncertain Origin\": (\"Presents reviews, ratings, or endorsements that lack verifiable \"\n",
    "                                                 \"sources or authenticity. They are designed to build false trust and \"\n",
    "                                                 \"persuade users to follow the supposed behavior of others.\"),\n",
    "        },\n",
    "    },\n",
    "    \"Scarcity\": {\n",
    "        \"Definition\": (\"Scarcity is a dark pattern that manipulates users by creating a false sense of limited \"\n",
    "                       \"availability. It pressures users into making decisions quickly by suggesting that a product \"\n",
    "                       \"or service may soon be unavailable. This tactic exploits fear of missing out (FOMO) to reduce \"\n",
    "                       \"thoughtful decision-making.\"),\n",
    "        \"Predicates\": {\n",
    "            \"Low-stock Messages\": (\"Displays warnings such as “Only 2 items left in stock” to pressure users into \"\n",
    "                                   \"purchasing. These messages may exaggerate or fabricate stock levels to induce urgency.\"),\n",
    "            \"High-demand Messages\": (\"Shows claims like “This product is in high demand” or “50 people are viewing this \"\n",
    "                                     \"right now.” Such messages create a sense of competition and urgency, often without \"\n",
    "                                     \"reliable evidence.\"),\n",
    "        },\n",
    "    },\n",
    "    \"Not Dark Pattern\": {\n",
    "        \"Predicates\": {\n",
    "            \"None\": \"Text that does not represent a dark pattern for this taxonomy.\",\n",
    "        },\n",
    "    },\n",
    "}\n",
    "\n",
    "# ------- Strong system prompt (contract-first) -------\n",
    "SYSTEM_PROMPT = (\n",
    "    \"ROLE: Dark-Pattern Expert Annotator.\\n\"\n",
    "    \"OUTPUT CONTRACT (MANDATORY): Return ONLY a single JSON object that validates the provided JSON Schema. \"\n",
    "    \"NO prose, NO markdown, NO explanations. \"\n",
    "    \"If uncertain, still choose the closest predicate and lower confidence.\\n\"\n",
    "    \"QUALITY: Be concise. Rationale <= 200 chars.\\n\"\n",
    ")\n",
    "\n",
    "USER_TEMPLATE = \"\"\"Assign the most specific predicate for the given text, constrained by the provided Type and its allowed predicates.\n",
    "\n",
    "Type: {type_name}\n",
    "\n",
    "Definitions:\n",
    "{type_def_block}\n",
    "\n",
    "Allowed predicates (choose exactly ONE, return the exact string):\n",
    "{allowed_list}\n",
    "\n",
    "Rules:\n",
    "- Pick exactly one allowed predicate for the given Type.\n",
    "- If the Type is \"Not Dark Pattern\", always return predicate \"None\".\n",
    "- Be conservative: if unclear, pick the closest predicate and lower confidence.\n",
    "- Base your decision ONLY on the text.\n",
    "\n",
    "Text:\n",
    "\\\"\\\"\\\"\n",
    "{snippet}\n",
    "\\\"\\\"\\\"\"\"\"\n",
    "\n",
    "# --------------- Helpers ---------------\n",
    "def normalize_type(t: str) -> str:\n",
    "    key = str(t).strip().lower()\n",
    "    return TYPE_NORMALIZE.get(key, t).strip()\n",
    "\n",
    "def build_type_block(type_name: str) -> str:\n",
    "    info = DEFINITIONS.get(type_name, {})\n",
    "    parts = []\n",
    "    if \"Definition\" in info:\n",
    "        parts.append(f\"- Definition: {info['Definition']}\")\n",
    "    preds = info.get(\"Predicates\", {})\n",
    "    if preds:\n",
    "        parts.append(\"- Predicate definitions:\")\n",
    "        for p, d in preds.items():\n",
    "            parts.append(f\"  * {p}: {d}\")\n",
    "    return \"\\n\".join(parts)\n",
    "\n",
    "def build_user_prompt(type_name: str, snippet: str) -> str:\n",
    "    allowed = PREDICATES[type_name]\n",
    "    allowed_list = \"\\n\".join(f\"- {p}\" for p in allowed)\n",
    "    block = build_type_block(type_name)\n",
    "    return USER_TEMPLATE.format(\n",
    "        type_name=type_name,\n",
    "        type_def_block=block,\n",
    "        allowed_list=allowed_list,\n",
    "        snippet=snippet\n",
    "    )\n",
    "\n",
    "def ensure_parent(path: str):\n",
    "    os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "\n",
    "def make_key(text: str, t: str) -> str:\n",
    "    return f\"{text}||{t}\"\n",
    "\n",
    "def load_existing_keys(path: str) -> Dict[str, bool]:\n",
    "    if not os.path.exists(path):\n",
    "        return {}\n",
    "    try:\n",
    "        prev = pd.read_csv(path)\n",
    "    except Exception:\n",
    "        return {}\n",
    "    if not {\"String\", \"Type\"}.issubset(set(prev.columns)):\n",
    "        return {}\n",
    "    return {make_key(str(r[\"String\"]), str(r[\"Type\"])): True for _, r in prev.iterrows()}\n",
    "\n",
    "def append_rows(path: str, rows: List[dict]):\n",
    "    ensure_parent(path)\n",
    "    df_new = pd.DataFrame(rows)\n",
    "    if os.path.exists(path):\n",
    "        base = pd.read_csv(path)\n",
    "        merged = pd.concat([base, df_new], ignore_index=True)\n",
    "    else:\n",
    "        merged = df_new\n",
    "    merged.to_csv(path, index=False, encoding=\"utf-8\")\n",
    "\n",
    "# --------- OpenAI plumbing (Responses API + JSON Schema) ---------\n",
    "def get_openai_client():\n",
    "    try:\n",
    "        from openai import OpenAI\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(\"Install openai>=1.0.0: pip install openai\") from e\n",
    "    return OpenAI()\n",
    "\n",
    "def build_json_schema(allowed_predicates: List[str]) -> dict:\n",
    "    return {\n",
    "        \"name\": \"PredicateLabel\",\n",
    "        \"schema\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"predicate\": {\"type\": \"string\", \"enum\": allowed_predicates},\n",
    "                \"confidence\": {\"type\": \"number\", \"minimum\": 0.0, \"maximum\": 1.0},\n",
    "                \"rationale\": {\"type\": \"string\", \"maxLength\": 200}\n",
    "            },\n",
    "            \"required\": [\"predicate\", \"confidence\", \"rationale\"],\n",
    "            \"additionalProperties\": False\n",
    "        },\n",
    "        \"strict\": True\n",
    "    }\n",
    "\n",
    "def _coerce_result(data: dict, allowed_predicates: list) -> dict:\n",
    "    \"\"\"모델 응답을 안전하게 보정: 누락 키/형식/범위/오탈자 처리.\"\"\"\n",
    "    out = {}\n",
    "\n",
    "    # predicate\n",
    "    pred = str(data.get(\"predicate\", \"\")).strip()\n",
    "    if pred == \"Pressured Seliing\":\n",
    "        pred = \"Pressured Selling\"\n",
    "    if pred not in allowed_predicates:\n",
    "        # 허용 셋에 없으면 가장 가까운 후보로 보정\n",
    "        # Not Dark Pattern이면 None 고정\n",
    "        pred = \"None\" if \"None\" in allowed_predicates else allowed_predicates[0]\n",
    "    out[\"predicate\"] = pred\n",
    "\n",
    "    # confidence\n",
    "    conf = data.get(\"confidence\", None)\n",
    "    try:\n",
    "        conf = float(conf)\n",
    "    except Exception:\n",
    "        # 텍스트에서 confidence 유추 시도 (e.g., \"confidence: 0.62\")\n",
    "        import re\n",
    "        m = re.search(r\"confidence\\s*[:=]\\s*([01](?:\\.\\d+)?)\", json.dumps(data), flags=re.I)\n",
    "        if m:\n",
    "            conf = float(m.group(1))\n",
    "        else:\n",
    "            conf = 0.5  # 기본값\n",
    "    # 0~1 클리핑\n",
    "    if conf < 0.0: conf = 0.0\n",
    "    if conf > 1.0: conf = 1.0\n",
    "    out[\"confidence\"] = conf\n",
    "\n",
    "    # rationale\n",
    "    rat = str(data.get(\"rationale\", \"\")).strip()\n",
    "    if not rat:\n",
    "        rat = \"Auto-filled rationale due to missing model field.\"\n",
    "    out[\"rationale\"] = rat[:300]\n",
    "    return out\n",
    "\n",
    "\n",
    "def call_openai(model: str, system_prompt: str, user_prompt: str, allowed_predicates: list) -> dict:\n",
    "    from openai import OpenAI\n",
    "    client = OpenAI()\n",
    "\n",
    "    backoff = 1.0\n",
    "    max_backoff = 30.0\n",
    "\n",
    "    # 공통 메시지\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt},\n",
    "    ]\n",
    "\n",
    "    # 함수 스키마 (tools/functions 겸용)\n",
    "    json_schema = {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"predicate\": {\"type\": \"string\", \"enum\": allowed_predicates},\n",
    "            \"confidence\": {\"type\": \"number\", \"minimum\": 0.0, \"maximum\": 1.0},\n",
    "            \"rationale\": {\"type\": \"string\", \"maxLength\": 200},\n",
    "        },\n",
    "        \"required\": [\"predicate\", \"confidence\", \"rationale\"],\n",
    "        \"additionalProperties\": False,\n",
    "    }\n",
    "    func_def_tools = [{\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"set_predicate\",\n",
    "            \"description\": \"Label the text with an allowed predicate, confidence (0..1), and a short rationale.\",\n",
    "            \"parameters\": json_schema,\n",
    "        }\n",
    "    }]\n",
    "    func_def_functions = [{\n",
    "        \"name\": \"set_predicate\",\n",
    "        \"description\": \"Label the text with an allowed predicate, confidence (0..1), and a short rationale.\",\n",
    "        \"parameters\": json_schema,\n",
    "    }]\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            # 1) 최신 방식: tools + tool_choice (일부 SDK만 지원)\n",
    "            try:\n",
    "                resp = client.chat.completions.create(\n",
    "                    model=model,\n",
    "                    messages=messages,\n",
    "                    temperature=0.0,\n",
    "                    tools=func_def_tools,\n",
    "                    tool_choice={\"type\": \"function\", \"function\": {\"name\": \"set_predicate\"}},\n",
    "                )\n",
    "                msg = resp.choices[0].message\n",
    "                if getattr(msg, \"tool_calls\", None):\n",
    "                    args = msg.tool_calls[0].function.arguments\n",
    "                    data = json.loads(args)\n",
    "                    return _coerce_result(data, allowed_predicates)\n",
    "                # tool_calls가 없으면 아래로 폴백\n",
    "            except TypeError:\n",
    "                pass  # tools 미지원 → functions로 폴백\n",
    "\n",
    "            # 2) 구버전: functions + function_call\n",
    "            try:\n",
    "                resp = client.chat.completions.create(\n",
    "                    model=model,\n",
    "                    messages=messages,\n",
    "                    temperature=0.0,\n",
    "                    functions=func_def_functions,\n",
    "                    function_call={\"name\": \"set_predicate\"},\n",
    "                )\n",
    "                msg = resp.choices[0].message\n",
    "                if getattr(msg, \"function_call\", None):\n",
    "                    args = msg.function_call.arguments\n",
    "                    data = json.loads(args)\n",
    "                    return _coerce_result(data, allowed_predicates)\n",
    "                # function_call이 없으면 아래로 폴백\n",
    "            except TypeError:\n",
    "                pass  # functions 미지원 → 일반 텍스트 폴백\n",
    "\n",
    "            # 3) 일반 텍스트 → JSON 파싱 시도 후 보정\n",
    "            resp = client.chat.completions.create(\n",
    "                model=model,\n",
    "                messages=messages,\n",
    "                temperature=0.0,\n",
    "            )\n",
    "            text = resp.choices[0].message.content or \"\"\n",
    "            # 코드펜스 제거\n",
    "            text = re.sub(r\"^```(?:json)?\\s*|\\s*```$\", \"\", text, flags=re.I | re.M).strip()\n",
    "            try:\n",
    "                data = json.loads(text)\n",
    "            except Exception:\n",
    "                # 매우 보수적으로 텍스트에서 predicate 라인만 추출 시도\n",
    "                # 예: \"predicate: Countdown Timers\"\n",
    "                import re\n",
    "                m = re.search(r\"predicate\\s*[:=]\\s*([^\\n\\r]+)\", text, flags=re.I)\n",
    "                pred_guess = m.group(1).strip() if m else \"\"\n",
    "                data = {\"predicate\": pred_guess, \"confidence\": 0.5, \"rationale\": text[:200]}\n",
    "            return _coerce_result(data, allowed_predicates)\n",
    "\n",
    "        except Exception as e:\n",
    "            msg = str(e).lower()\n",
    "            if any(s in msg for s in [\"rate\", \"timeout\", \"overloaded\", \"temporarily\", \"503\", \"502\"]):\n",
    "                import time\n",
    "                time.sleep(backoff)\n",
    "                backoff = min(max_backoff, backoff * 2.0)\n",
    "                continue\n",
    "            raise\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# --------------- Core ---------------\n",
    "def label_merged(df: pd.DataFrame, target_types: List[str], model: str):\n",
    "    ensure_parent(OUT_PATH)\n",
    "    done_keys = load_existing_keys(OUT_PATH)\n",
    "\n",
    "    for type_name in target_types:\n",
    "        subset = df[df[\"Type\"] == type_name].copy()\n",
    "        if subset.empty:\n",
    "            print(f\"[skip] No rows for Type={type_name}\")\n",
    "            continue\n",
    "\n",
    "        allowed = list(PREDICATES[type_name])  # JSON schema enum needs a list\n",
    "        rows_buffer: List[dict] = []\n",
    "        total = len(subset)\n",
    "        processed = 0\n",
    "\n",
    "        for _, row in subset.iterrows():\n",
    "            text = str(row[\"String\"]).strip()\n",
    "            key = make_key(text, type_name)\n",
    "            if key in done_keys:  # resumable: skip already processed\n",
    "                processed += 1\n",
    "                continue\n",
    "\n",
    "            prompt = build_user_prompt(type_name, text)\n",
    "            result = call_openai(model, SYSTEM_PROMPT, prompt, allowed_predicates=allowed)\n",
    "\n",
    "            pred = result.get(\"predicate\", \"\")\n",
    "            if pred not in allowed:\n",
    "                pred = \"None\" if type_name == \"Not Dark Pattern\" else allowed[0]\n",
    "\n",
    "            out_row = {\n",
    "                \"String\": text,\n",
    "                \"Type\": type_name,\n",
    "                \"label\": int(row.get(\"label\", 0)),\n",
    "                \"predicate\": pred,\n",
    "                \"confidence\": float(result.get(\"confidence\", 0.0)),\n",
    "                \"rationale\": str(result.get(\"rationale\", \"\"))[:300],\n",
    "            }\n",
    "            rows_buffer.append(out_row)\n",
    "            done_keys[key] = True\n",
    "            processed += 1\n",
    "\n",
    "            # Periodic flush\n",
    "            if len(rows_buffer) >= 50:\n",
    "                append_rows(OUT_PATH, rows_buffer)\n",
    "                rows_buffer.clear()\n",
    "                print(f\"  ...[{type_name}] progress {processed}/{total} → {OUT_PATH}\")\n",
    "\n",
    "        if rows_buffer:\n",
    "            append_rows(OUT_PATH, rows_buffer)\n",
    "            rows_buffer.clear()\n",
    "        print(f\"[done] {type_name}: appended to {OUT_PATH}\")\n",
    "\n",
    "def main():\n",
    "    ap = argparse.ArgumentParser(description=\"Merged predicate labeling using OpenAI Responses API (single CSV output).\")\n",
    "    ap.add_argument(\"--input\", default=DEFAULT_INPUT, help=\"Path to CSV (default: data/processed/template.csv)\")\n",
    "    ap.add_argument(\"--model\", default=DEFAULT_MODEL, help=\"OpenAI model (default: gpt-4.1-mini)\")\n",
    "    ap.add_argument(\"--types\", default=\"all\", help='Comma-separated list of Types or \"all\"')\n",
    "    args = ap.parse_args()\n",
    "\n",
    "    # Load input\n",
    "    df = pd.read_csv(args.input)\n",
    "\n",
    "    # Normalize and filter to canonical 5\n",
    "    df[\"Type\"] = df[\"Type\"].map(lambda x: normalize_type(x))\n",
    "    df = df[df[\"Type\"].isin(CANONICAL_TYPES)].copy()\n",
    "\n",
    "    # Pick target types\n",
    "    if args.types.strip().lower() == \"all\":\n",
    "        target_types = CANONICAL_TYPES\n",
    "    else:\n",
    "        raw_parts = [t.strip() for t in args.types.split(\",\") if t.strip()]\n",
    "        target_types = []\n",
    "        for p in raw_parts:\n",
    "            n = normalize_type(p)\n",
    "            if n not in CANONICAL_TYPES:\n",
    "                raise ValueError(f\"Unknown Type '{p}'. Must be one of: {CANONICAL_TYPES}\")\n",
    "            target_types.append(n)\n",
    "\n",
    "    label_merged(df, target_types, args.model)\n",
    "    print(f\"[OK] All done. Merged output at: {OUT_PATH}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import sys\n",
    "    # Jupyter Notebook에서 실행될 때는 불필요한 인자 제거\n",
    "    if \"ipykernel_launcher\" in sys.argv[0]:\n",
    "        sys.argv = [sys.argv[0], \"--input\", \"../data/processed/template.csv\", \"--model\", \"gpt-4o\"]\n",
    "    main()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
