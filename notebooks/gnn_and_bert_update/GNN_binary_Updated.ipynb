{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8023,"status":"ok","timestamp":1758125895835,"user":{"displayName":"ë°•í˜„ìš°","userId":"01265894329339476871"},"user_tz":-540},"id":"G6bxgXC6d_HH","outputId":"d1d01d48-92a8-4390-aea1-05e4e2ebcf87"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"1-SfUNu5d02W","outputId":"c676b3a3-ee76-436d-f5bf-21af92f75f58"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in links: https://data.pyg.org/whl/torch-2.8.0+cu126.html\n","Collecting torch-scatter\n","  Downloading https://data.pyg.org/whl/torch-2.8.0%2Bcu126/torch_scatter-2.1.2%2Bpt28cu126-cp312-cp312-linux_x86_64.whl (10.9 MB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting torch-sparse\n","  Downloading https://data.pyg.org/whl/torch-2.8.0%2Bcu126/torch_sparse-0.6.18%2Bpt28cu126-cp312-cp312-linux_x86_64.whl (5.2 MB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m40.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting torch-cluster\n","  Downloading https://data.pyg.org/whl/torch-2.8.0%2Bcu126/torch_cluster-1.6.3%2Bpt28cu126-cp312-cp312-linux_x86_64.whl (3.3 MB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting torch-spline-conv\n","  Downloading https://data.pyg.org/whl/torch-2.8.0%2Bcu126/torch_spline_conv-1.2.2%2Bpt28cu126-cp312-cp312-linux_x86_64.whl (1.1 MB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m36.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from torch-sparse) (1.16.1)\n","Requirement already satisfied: numpy<2.6,>=1.25.2 in /usr/local/lib/python3.12/dist-packages (from scipy->torch-sparse) (2.0.2)\n","Installing collected packages: torch-spline-conv, torch-scatter, torch-sparse, torch-cluster\n","Successfully installed torch-cluster-1.6.3+pt28cu126 torch-scatter-2.1.2+pt28cu126 torch-sparse-0.6.18+pt28cu126 torch-spline-conv-1.2.2+pt28cu126\n","Collecting torch-geometric\n","  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.12.15)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2025.3.0)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.1.6)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2.0.2)\n","Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (5.9.5)\n","Requirement already satisfied: pyparsing in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.2.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2.32.4)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (4.67.1)\n","Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (2.6.1)\n","Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.4.0)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (25.3.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.7.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (6.6.4)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (0.3.2)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.20.1)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch-geometric) (3.0.2)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (3.4.3)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (2025.8.3)\n","Requirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.12/dist-packages (from aiosignal>=1.4.0->aiohttp->torch-geometric) (4.15.0)\n","Downloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: torch-geometric\n","Successfully installed torch-geometric-2.6.1\n","Using device: cpu\n","âœ… ë°ì´í„°ì…‹ ë¡œë“œ ì™„ë£Œ.\n","\n","====================\n","ğŸš€ CONTEXTUAL ë°ì´í„°ì…‹ GNN íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì‹œì‘\n","====================\n","ê²°ê³¼ ì €ì¥ ê²½ë¡œ: /content/drive/MyDrive/ì¡¸ì—…ë…¼ë¬¸/models/gnn_contextual_model\n"]},{"name":"stderr","output_type":"stream","text":["/tmp/ipython-input-517508704.py:112: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n","The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n","\n","For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n","\n","\n","  df['predicate'].fillna('Not Dark Pattern', inplace=True)\n"]},{"ename":"KeyError","evalue":"'sentence'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3805\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3806\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n","\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 'sentence'","\nThe above exception was the direct cause of the following exception:\n","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-517508704.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    286\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m             \u001b[0mrun_gnn_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbase_save_directory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    289\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"âš ï¸ {name} ë°ì´í„°ì…‹ì´ ë¹„ì–´ìˆê±°ë‚˜ ë¡œë“œë˜ì§€ ì•Šì•„ ê±´ë„ˆëœë‹ˆë‹¤.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipython-input-517508704.py\u001b[0m in \u001b[0;36mrun_gnn_pipeline\u001b[0;34m(df, dataset_name, base_save_dir)\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[0;31m# --- 2. ë°ì´í„° ì „ì²˜ë¦¬ ë° ë¼ë²¨ ì¸ì½”ë”© ---\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'predicate'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Not Dark Pattern'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m     \u001b[0msentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sentence'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m     \u001b[0mlabels_raw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'predicate'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4101\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4102\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4103\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4104\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3810\u001b[0m             ):\n\u001b[1;32m   3811\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mInvalidIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3812\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3813\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3814\u001b[0m             \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 'sentence'"]}],"source":["# ======================================================\n","# Cell 1. ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ ë° ê¸°ë³¸ ì„¤ì •\n","# ======================================================\n","# PyTorch Geometric (PyG) ë° ê´€ë ¨ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜\n","import torch\n","import os\n","\n","# PyTorch ë²„ì „ì— ë§ëŠ” PyG ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜\n","!pip install torch-scatter torch-sparse torch-cluster torch-spline-conv -f https://data.pyg.org/whl/torch-{torch.__version__}.html\n","!pip install torch-geometric\n","\n","# Hugging Face ë° ê¸°íƒ€ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜\n","!pip install -q transformers datasets scikit-learn pandas numpy matplotlib seaborn networkx\n","\n","# ê¸°ë³¸ ì„¤ì •\n","DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","print(f\"Using device: {DEVICE}\")\n","\n","# ======================================================\n","# Cell 2. ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬\n","# ======================================================\n","import pandas as pd\n","from sklearn.preprocessing import LabelEncoder\n","import numpy as np\n","\n","# ë°ì´í„°ì…‹ ê²½ë¡œ ì„¤ì •\n","base_path = '/content/drive/MyDrive/ì¡¸ì—…ë…¼ë¬¸/data/processed/'\n","contextual_path = os.path.join(base_path, 'contextual_merged.csv')\n","paraphrase_path = os.path.join(base_path, 'paraphrase_merged.csv')\n","template_path = os.path.join(base_path, 'template_merged.csv')\n","\n","# ë°ì´í„°í”„ë ˆì„ ë¡œë“œ\n","try:\n","    contextual_df = pd.read_csv(contextual_path)\n","    paraphrase_df = pd.read_csv(paraphrase_path)\n","    template_df = pd.read_csv(template_path) # ë³€ìˆ˜ëª… ì˜¤íƒ€ ìˆ˜ì • (templete -> template)\n","    print(\"âœ… ë°ì´í„°ì…‹ ë¡œë“œ ì™„ë£Œ.\")\n","except FileNotFoundError as e:\n","    print(f\"ğŸš¨ íŒŒì¼ ë¡œë“œ ì˜¤ë¥˜: {e}\")\n","    print(\"íŒŒì¼ ê²½ë¡œë¥¼ ë‹¤ì‹œ í™•ì¸í•´ì£¼ì„¸ìš”. ì˜ˆ: /content/drive/MyDrive/path/to/your/data.csv\")\n","    # íŒŒì¼ì´ ì—†ìœ¼ë©´ ì´í›„ ì½”ë“œ ì‹¤í–‰ì„ ì¤‘ë‹¨\n","    # ì‹¤ì œ í™˜ê²½ì—ì„œëŠ” ì´ ë¶€ë¶„ì—ì„œ ì‹¤í–‰ì„ ë©ˆì¶”ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤.\n","    contextual_df, paraphrase_df, template_df = None, None, None\n","\n","datasets = {\n","    \"contextual\": contextual_df,\n","    \"paraphrase\": paraphrase_df,\n","    \"template\": template_df\n","}\n","\n","# ======================================================\n","# Cell 3. GNN ëª¨ë¸ ë° í•™ìŠµ ë£¨í”„ ì •ì˜\n","# ======================================================\n","from tqdm.notebook import tqdm\n","from transformers import AutoTokenizer, AutoModel\n","from sklearn.neighbors import NearestNeighbors\n","import torch.nn.functional as F\n","from torch_geometric.data import Data\n","from torch_geometric.nn import GCNConv\n","from sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report, confusion_matrix\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import networkx as nx\n","from torch_geometric.utils import to_networkx\n","\n","# --- GCN ëª¨ë¸ ì •ì˜ ---\n","class GCNClassifier(torch.nn.Module):\n","    def __init__(self, in_dim, hidden_dim, out_dim, n_layers=2, dropout=0.5):\n","        super().__init__()\n","        self.convs = torch.nn.ModuleList()\n","        self.convs.append(GCNConv(in_dim, hidden_dim))\n","        for _ in range(n_layers - 1):\n","            self.convs.append(GCNConv(hidden_dim, hidden_dim))\n","        self.lin = torch.nn.Linear(hidden_dim, out_dim)\n","        self.dropout = dropout\n","\n","    def forward(self, x, edge_index):\n","        for conv in self.convs:\n","            x = conv(x, edge_index)\n","            x = F.relu(x)\n","            x = F.dropout(x, p=self.dropout, training=self.training)\n","        out = self.lin(x)\n","        return out\n","\n","# --- í‰ê·  í’€ë§ í•¨ìˆ˜ ---\n","def mean_pooling(model_output, attention_mask):\n","    token_embeddings = model_output[0]\n","    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n","    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n","\n","# --- í•™ìŠµ ë° í‰ê°€ íŒŒì´í”„ë¼ì¸ í•¨ìˆ˜ ---\n","def run_gnn_pipeline(df, dataset_name, base_save_dir):\n","    print(\"\\n\" + \"=\"*20)\n","    print(f\"ğŸš€ {dataset_name.upper()} ë°ì´í„°ì…‹ GNN íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì‹œì‘\")\n","    print(\"=\"*20)\n","\n","    # --- 0. íŒŒë¼ë¯¸í„° ì„¤ì • ---\n","    EMBED_MODEL = \"sentence-transformers/all-MiniLM-L6-v2\"\n","    K_NEIGHBORS = 8\n","    HIDDEN_DIM = 128\n","    GNN_LAYERS = 2\n","    LR = 0.01\n","    EPOCHS = 200 # í•™ìŠµ ì„±ëŠ¥ì„ ìœ„í•´ Epochs ì¦ê°€\n","    BATCH_SIZE = 32\n","\n","    # --- 1. ê²°ê³¼ ì €ì¥ ë””ë ‰í† ë¦¬ ìƒì„± ---\n","    SAVE_DIR = os.path.join(base_save_dir, f\"gnn_{dataset_name}_model\")\n","    os.makedirs(SAVE_DIR, exist_ok=True)\n","    print(f\"ê²°ê³¼ ì €ì¥ ê²½ë¡œ: {SAVE_DIR}\")\n","\n","    # --- 2. ë°ì´í„° ì „ì²˜ë¦¬ ë° ë¼ë²¨ ì¸ì½”ë”© ---\n","    df['predicate'].fillna('Not Dark Pattern', inplace=True)\n","    sentences = df['sentence'].tolist()\n","    labels_raw = df['predicate'].tolist()\n","\n","    target_name = \"Not Dark Pattern\"\n","    binary_labels = [1 if label == target_name else 0 for label in labels_raw]\n","    labels_enc = np.array(binary_labels)\n","    num_classes = len(np.unique(labels_enc))\n","\n","    # LabelEncoderëŠ” í´ë˜ìŠ¤ ì´ë¦„ ì‹œê°í™”ë¥¼ ìœ„í•´ ì‚¬ìš©\n","    le = LabelEncoder()\n","    le.fit([0, 1]) # 0: Dark Pattern, 1: Not Dark Pattern\n","    le.classes_ = np.array([f'Dark Pattern (0)', f'{target_name} (1)'])\n","\n","\n","    print(f\"ë°ì´í„° ìƒ˜í”Œ ìˆ˜: {len(sentences)}\")\n","    print(f\"í´ë˜ìŠ¤ ìˆ˜: {num_classes}\")\n","    print(f\"í´ë˜ìŠ¤: {le.classes_}\")\n","\n","    # --- 3. ë¬¸ì¥ ì„ë² ë”© ìƒì„± ---\n","    embed_tokenizer = AutoTokenizer.from_pretrained(EMBED_MODEL)\n","    embed_model = AutoModel.from_pretrained(EMBED_MODEL).to(DEVICE)\n","    embed_model.eval()\n","\n","    all_embeddings = []\n","    for i in tqdm(range(0, len(sentences), BATCH_SIZE), desc=f\"[{dataset_name}] Embedding\"):\n","        batch_texts = sentences[i:i+BATCH_SIZE]\n","        inputs = embed_tokenizer(batch_texts, padding=True, truncation=True, return_tensors=\"pt\").to(DEVICE)\n","        with torch.no_grad():\n","            outputs = embed_model(**inputs)\n","            emb = mean_pooling(outputs, inputs['attention_mask'])\n","            emb = emb.cpu().numpy()\n","        all_embeddings.append(emb)\n","    all_embeddings = np.vstack(all_embeddings)\n","    print(f\"ì„ë² ë”© Shape: {all_embeddings.shape}\")\n","\n","    # --- 4. kNN ê·¸ë˜í”„ ìƒì„± ---\n","    emb = all_embeddings\n","    n_neighbors = min(K_NEIGHBORS, len(emb) - 1)\n","    nbrs = NearestNeighbors(n_neighbors=n_neighbors + 1, metric=\"cosine\").fit(emb)\n","    _, indices = nbrs.kneighbors(emb)\n","\n","    edge_index_list = []\n","    for i in range(len(indices)):\n","        for j in indices[i][1:]:\n","            edge_index_list.append((i, j))\n","            edge_index_list.append((j, i))\n","    edge_index = np.array(edge_index_list).T\n","    print(f\"Edge index Shape: {edge_index.shape}\")\n","\n","    # --- 5. PyG Data ê°ì²´ ìƒì„± ---\n","    x = torch.tensor(emb, dtype=torch.float)\n","    y = torch.tensor(labels_enc, dtype=torch.long)\n","    edge_index_t = torch.tensor(edge_index, dtype=torch.long)\n","\n","    data = Data(x=x, edge_index=edge_index_t, y=y)\n","\n","    num_nodes = data.num_nodes\n","    perm = np.random.permutation(num_nodes)\n","    train_ratio = 0.8\n","    n_train = int(train_ratio * num_nodes)\n","    train_idx, val_idx = perm[:n_train], perm[n_train:]\n","\n","    data.train_mask = torch.zeros(num_nodes, dtype=torch.bool)\n","    data.val_mask = torch.zeros(num_nodes, dtype=torch.bool)\n","    data.train_mask[train_idx] = True\n","    data.val_mask[val_idx] = True\n","    print(data)\n","\n","    # --- 6. GNN ëª¨ë¸ ì´ˆê¸°í™” ---\n","    model_gnn = GCNClassifier(in_dim=x.size(1), hidden_dim=HIDDEN_DIM, out_dim=num_classes, n_layers=GNN_LAYERS).to(DEVICE)\n","    optimizer = torch.optim.Adam(model_gnn.parameters(), lr=LR, weight_decay=1e-5)\n","    criterion = torch.nn.CrossEntropyLoss()\n","    data = data.to(DEVICE)\n","\n","    # --- 7. í•™ìŠµ ë£¨í”„ ---\n","    best_val_f1 = 0\n","    best_epoch = 0\n","    print(\"\\n GNN ëª¨ë¸ í•™ìŠµ ì‹œì‘...\")\n","    for epoch in range(1, EPOCHS + 1):\n","        model_gnn.train()\n","        optimizer.zero_grad()\n","        out = model_gnn(data.x, data.edge_index)\n","        loss = criterion(out[data.train_mask], data.y[data.train_mask])\n","        loss.backward()\n","        optimizer.step()\n","\n","        # Validation\n","        model_gnn.eval()\n","        with torch.no_grad():\n","            out_val = model_gnn(data.x, data.edge_index)\n","            preds_val = out_val[data.val_mask].argmax(dim=1).cpu().numpy()\n","            true_val = data.y[data.val_mask].cpu().numpy()\n","            val_acc = accuracy_score(true_val, preds_val)\n","            p, r, f, _ = precision_recall_fscore_support(true_val, preds_val, average='binary', zero_division=0)\n","\n","        if f > best_val_f1:\n","            best_val_f1 = f\n","            best_epoch = epoch\n","            torch.save(model_gnn.state_dict(), os.path.join(SAVE_DIR, \"gnn_model.pt\"))\n","\n","\n","        if epoch % 20 == 0:\n","            print(f\"Epoch {epoch:03d} | Loss: {loss:.4f} | Val Acc: {val_acc:.4f} | Val F1: {f:.4f}\")\n","\n","    print(f\"âœ… í•™ìŠµ ì™„ë£Œ. Best F1: {best_val_f1:.4f} at Epoch {best_epoch}\")\n","    print(f\"ìµœì  ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {os.path.join(SAVE_DIR, 'gnn_model.pt')}\")\n","\n","\n","    # --- 8. ìµœì¢… í‰ê°€ ë° ê²°ê³¼ ì €ì¥ ---\n","    # ìµœì  ëª¨ë¸ ë¡œë“œ\n","    model_gnn.load_state_dict(torch.load(os.path.join(SAVE_DIR, \"gnn_model.pt\")))\n","    model_gnn.eval()\n","    with torch.no_grad():\n","        out_final = model_gnn(data.x, data.edge_index)\n","        preds = out_final.argmax(dim=1).cpu().numpy()\n","\n","    # ì˜ˆì¸¡ ê²°ê³¼ ì €ì¥\n","    df_res = pd.DataFrame({\n","        \"sentence\": sentences,\n","        \"true_label\": labels_raw,\n","        \"true_label_enc\": labels_enc,\n","        \"pred_label_enc\": preds\n","    })\n","    pred_path = os.path.join(SAVE_DIR, \"gnn_predictions.csv\")\n","    df_res.to_csv(pred_path, index=False, encoding=\"utf-8-sig\")\n","    print(f\"ì˜ˆì¸¡ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {pred_path}\")\n","\n","    # ìµœì¢… ì„±ëŠ¥ ë¦¬í¬íŠ¸\n","    y_true_all = df_res['true_label_enc']\n","    y_pred_all = df_res['pred_label_enc']\n","    class_names = le.classes_\n","    report = classification_report(y_true_all, y_pred_all, target_names=[str(name) for name in class_names])\n","    print(\"\\n\" + \"=\"*15, \"ìµœì¢… ì„±ëŠ¥ í‰ê°€ ë¦¬í¬íŠ¸\", \"=\"*15)\n","    print(report)\n","    print(\"=\"*55)\n","\n","    # Confusion Matrix ì‹œê°í™”\n","    cm = confusion_matrix(y_true_all, y_pred_all)\n","    plt.figure(figsize=(8, 6))\n","    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n","    plt.xlabel('Predicted Label')\n","    plt.ylabel('True Label')\n","    plt.title(f'GNN Model Confusion Matrix ({dataset_name})')\n","    cm_path = os.path.join(SAVE_DIR, \"gnn_confusion_matrix.png\")\n","    plt.savefig(cm_path)\n","    plt.show()\n","    print(f\"Confusion Matrix ì €ì¥ ì™„ë£Œ: {cm_path}\")\n","\n","    # kNN ê·¸ë˜í”„ ì‹œê°í™”\n","    G = to_networkx(data.cpu(), to_undirected=True)\n","    color_map = ['#ff7f0e' if label == 0 else '#1f77b4' for label in data.y.cpu().numpy()]\n","    plt.figure(figsize=(15, 15))\n","    pos = nx.spring_layout(G, iterations=50, seed=42)\n","    nx.draw(G, pos, node_color=color_map, with_labels=False, node_size=60, width=0.5, edge_color='grey')\n","    plt.title(f'kNN Graph of Sentence Embeddings ({dataset_name})', fontsize=20)\n","\n","    blue_patch = plt.scatter([],[], c='#1f77b4', label=f'Class 1 ({target_name})')\n","    orange_patch = plt.scatter([],[], c='#ff7f0e', label=f'Class 0 (Dark Pattern)')\n","    plt.legend(handles=[blue_patch, orange_patch], loc='upper right', fontsize=14, title='Labels')\n","\n","    graph_path = os.path.join(SAVE_DIR, \"gnn_graph.png\")\n","    plt.savefig(graph_path, dpi=300, bbox_inches='tight')\n","    plt.show()\n","    print(f\"GNN ê·¸ë˜í”„ ì €ì¥ ì™„ë£Œ: {graph_path}\")\n","    print(f\"ğŸ‰ {dataset_name.upper()} ë°ì´í„°ì…‹ íŒŒì´í”„ë¼ì¸ ì¢…ë£Œ.\")\n","\n","\n","# ======================================================\n","# Cell 4. ë©”ì¸ ì‹¤í–‰ ë£¨í”„\n","# ======================================================\n","base_save_directory = '/content/drive/MyDrive/ì¡¸ì—…ë…¼ë¬¸/models/'\n","\n","if all(df is not None for df in datasets.values()):\n","    for name, df in datasets.items():\n","        if df is not None and not df.empty:\n","            run_gnn_pipeline(df.copy(), name, base_save_directory)\n","        else:\n","            print(f\"âš ï¸ {name} ë°ì´í„°ì…‹ì´ ë¹„ì–´ìˆê±°ë‚˜ ë¡œë“œë˜ì§€ ì•Šì•„ ê±´ë„ˆëœë‹ˆë‹¤.\")\n","else:\n","    print(\"ğŸš¨ ë°ì´í„°ì…‹ ë¡œë“œì— ì‹¤íŒ¨í•˜ì—¬ GNN íŒŒì´í”„ë¼ì¸ì„ ì‹¤í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lf6ZMnBcd3ms"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[],"mount_file_id":"1nmXhZ0o0ECPmv5vxyRBcPFccR8aDQauF","authorship_tag":"ABX9TyNkus+fn3bpGevFdYkAB20N"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}