{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a9957d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 클래스별 샘플 수 ===\n",
      "predicate\n",
      "activity notifications    499\n",
      "confirmshaming            298\n",
      "pressured selling         140\n",
      "trick questions            62\n",
      "Name: count, dtype: int64 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hg/mhc8mjsj749cspxfbjl1tz8m0000gn/T/ipykernel_1953/3613127512.py:152: MatplotlibDeprecationWarning: The 'labels' parameter of boxplot() has been renamed 'tick_labels' since Matplotlib 3.9; support for the old name will be dropped in 3.11.\n",
      "  plt.boxplot(d, vert=True, labels=[c])\n",
      "/var/folders/hg/mhc8mjsj749cspxfbjl1tz8m0000gn/T/ipykernel_1953/3613127512.py:152: MatplotlibDeprecationWarning: The 'labels' parameter of boxplot() has been renamed 'tick_labels' since Matplotlib 3.9; support for the old name will be dropped in 3.11.\n",
      "  plt.boxplot(d, vert=True, labels=[c])\n",
      "/var/folders/hg/mhc8mjsj749cspxfbjl1tz8m0000gn/T/ipykernel_1953/3613127512.py:152: MatplotlibDeprecationWarning: The 'labels' parameter of boxplot() has been renamed 'tick_labels' since Matplotlib 3.9; support for the old name will be dropped in 3.11.\n",
      "  plt.boxplot(d, vert=True, labels=[c])\n",
      "/var/folders/hg/mhc8mjsj749cspxfbjl1tz8m0000gn/T/ipykernel_1953/3613127512.py:152: MatplotlibDeprecationWarning: The 'labels' parameter of boxplot() has been renamed 'tick_labels' since Matplotlib 3.9; support for the old name will be dropped in 3.11.\n",
      "  plt.boxplot(d, vert=True, labels=[c])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette (cosine): 0.062\n",
      "SVD explained variance ratio (2D sum): 0.076\n",
      "\n",
      "=== Logistic Regression (OVR) on TF-IDF ===\n",
      "                        precision    recall  f1-score   support\n",
      "\n",
      "activity notifications       0.89      1.00      0.94       100\n",
      "        confirmshaming       0.98      1.00      0.99        60\n",
      "     pressured selling       1.00      0.71      0.83        28\n",
      "       trick questions       1.00      0.58      0.74        12\n",
      "\n",
      "              accuracy                           0.94       200\n",
      "             macro avg       0.97      0.82      0.88       200\n",
      "          weighted avg       0.94      0.94      0.93       200\n",
      "\n",
      "\n",
      "완료! 결과 이미지/CSV는 'dp_dist/' 폴더에 저장되었습니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/soyoung/404DNF_AI/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1281: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n",
      "/Users/soyoung/404DNF_AI/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# 4개 predicate(Confirmshaming / Trick Questions / Pressured Selling / Activity Notifications)\n",
    "# 유사도 & 분포 한방 분석 스크립트\n",
    "# - TF-IDF(word 1~3-gram + char 3~5-gram)\n",
    "# - Centroid 코사인/유클리드 + 히트맵\n",
    "# - Intra/Inter 코사인 분포(히스토그램)\n",
    "# - 거리(샘플↔자기 클래스 centroid) 분포(히스토그램/박스)\n",
    "# - Silhouette 점수 분포(히스토그램)\n",
    "# - 2D 임베딩(TruncatedSVD) 산점도\n",
    "# - Centroid 덴드로그램(계층 군집)\n",
    "# - (옵션) 샘플링 pairwise cosine 히트맵\n",
    "# ============================================\n",
    "\n",
    "import os, re, itertools, numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity, euclidean_distances\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import silhouette_score, silhouette_samples\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from scipy.sparse import hstack\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram\n",
    "from scipy.spatial.distance import squareform\n",
    "\n",
    "# ------------------ 설정 ------------------\n",
    "FILE_PATH = \"/Users/soyoung/404DNF_AI/data/processed/template_predicate.csv\"      # 필요시 경로 변경\n",
    "OUTPUT_DIR = \"dp_dist\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "TARGET_PREDICATES = [\n",
    "    \"confirmshaming\",\n",
    "    \"trick questions\",\n",
    "    \"pressured selling\",\n",
    "    \"activity notifications\",\n",
    "]\n",
    "\n",
    "# ------------------ 1) 데이터 로드/필터 ------------------\n",
    "df = pd.read_csv(FILE_PATH)\n",
    "assert {\"String\", \"predicate\"} <= set(df.columns), \"CSV에 String, predicate 컬럼이 필요합니다.\"\n",
    "df = df.dropna(subset=[\"String\", \"predicate\"]).copy()\n",
    "df[\"predicate\"] = df[\"predicate\"].str.lower().str.strip()\n",
    "\n",
    "mask = df[\"predicate\"].isin([p.lower() for p in TARGET_PREDICATES])\n",
    "data = df.loc[mask].reset_index(drop=True)\n",
    "if data.empty:\n",
    "    raise ValueError(\"선택한 predicate가 데이터에 없습니다.\")\n",
    "\n",
    "print(\"=== 클래스별 샘플 수 ===\")\n",
    "print(data[\"predicate\"].value_counts(), \"\\n\")\n",
    "\n",
    "# ------------------ 2) 텍스트 정제 ------------------\n",
    "def clean_keep_nums(s: str) -> str:\n",
    "    s = s.lower()\n",
    "    s = re.sub(r\"http\\S+|www\\.\\S+\", \" \", s)\n",
    "    # 숫자/%, $ 유지(가격/카운트류 신호 보존)\n",
    "    s = re.sub(r\"[^a-z0-9\\s%$]\", \" \", s)\n",
    "    s = re.sub(r\"\\s+\", \" \", s).strip()\n",
    "    return s\n",
    "\n",
    "data[\"text_clean\"] = data[\"String\"].astype(str).apply(clean_keep_nums)\n",
    "\n",
    "# ------------------ 3) TF-IDF (word + char) ------------------\n",
    "wvec = TfidfVectorizer(stop_words=\"english\", ngram_range=(1,3), min_df=1, max_df=0.95, norm=\"l2\")\n",
    "cvec = TfidfVectorizer(analyzer=\"char_wb\", ngram_range=(3,5), min_df=2, norm=\"l2\")\n",
    "Xw = wvec.fit_transform(data[\"text_clean\"])\n",
    "Xc = cvec.fit_transform(data[\"text_clean\"])\n",
    "X  = hstack([Xw, Xc])  # csr_matrix\n",
    "\n",
    "labels = data[\"predicate\"].values\n",
    "classes = sorted(pd.unique(labels))\n",
    "\n",
    "# ------------------ 4) Centroid 유사도/거리 + 히트맵 ------------------\n",
    "centroids = []\n",
    "for c in classes:\n",
    "    rows = X[labels == c]\n",
    "    centroids.append(np.asarray(rows.mean(axis=0)).ravel())\n",
    "centroids = np.vstack(centroids)\n",
    "\n",
    "centroid_cos = cosine_similarity(centroids)\n",
    "centroid_euc = euclidean_distances(centroids)\n",
    "\n",
    "centroid_cos_df = pd.DataFrame(centroid_cos, index=classes, columns=classes)\n",
    "centroid_euc_df = pd.DataFrame(centroid_euc, index=classes, columns=classes)\n",
    "centroid_cos_df.to_csv(os.path.join(OUTPUT_DIR, \"centroid_cosine.csv\"))\n",
    "centroid_euc_df.to_csv(os.path.join(OUTPUT_DIR, \"centroid_euclidean.csv\"))\n",
    "\n",
    "def heatmap(mat, ticks, title, path):\n",
    "    plt.figure(figsize=(6,5))\n",
    "    im = plt.imshow(mat, interpolation=\"nearest\")\n",
    "    plt.colorbar(im, fraction=0.046, pad=0.04)\n",
    "    plt.xticks(range(len(ticks)), ticks, rotation=45, ha=\"right\")\n",
    "    plt.yticks(range(len(ticks)), ticks)\n",
    "    plt.title(title)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(path, dpi=150)\n",
    "    plt.close()\n",
    "\n",
    "heatmap(centroid_cos_df.values, classes, \"Centroid Cosine Similarity\", os.path.join(OUTPUT_DIR, \"centroid_cosine_heatmap.png\"))\n",
    "heatmap(centroid_euc_df.values, classes, \"Centroid Euclidean Distance\", os.path.join(OUTPUT_DIR, \"centroid_euclidean_heatmap.png\"))\n",
    "\n",
    "# ------------------ 5) Intra/Inter 분포(히스토그램) ------------------\n",
    "# Intra: 같은 클래스 내 pairwise cosine\n",
    "for c in classes:\n",
    "    idx = np.where(labels == c)[0]\n",
    "    if len(idx) < 2:\n",
    "        continue\n",
    "    sub = X[idx]\n",
    "    S = cosine_similarity(sub)\n",
    "    # 상삼각(대각 제외)만 취해 분포 생성\n",
    "    triu = np.triu_indices_from(S, k=1)\n",
    "    vals = S[triu]\n",
    "    plt.figure(figsize=(6,4))\n",
    "    plt.hist(vals, bins=30)\n",
    "    plt.title(f\"Intra-class Cosine Distribution: {c}\")\n",
    "    plt.xlabel(\"cosine\")\n",
    "    plt.ylabel(\"count\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(OUTPUT_DIR, f\"intra_cosine_hist_{c.replace(' ','_')}.png\"), dpi=150)\n",
    "    plt.close()\n",
    "\n",
    "# Inter: 서로 다른 클래스 간 pairwise cosine\n",
    "for a, b in itertools.combinations(classes, 2):\n",
    "    Sa = X[labels == a]; Sb = X[labels == b]\n",
    "    S = cosine_similarity(Sa, Sb).ravel()\n",
    "    plt.figure(figsize=(6,4))\n",
    "    plt.hist(S, bins=30)\n",
    "    plt.title(f\"Inter-class Cosine Distribution: {a} vs {b}\")\n",
    "    plt.xlabel(\"cosine\")\n",
    "    plt.ylabel(\"count\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(OUTPUT_DIR, f\"inter_cosine_hist_{a.replace(' ','_')}__{b.replace(' ','_')}.png\"), dpi=150)\n",
    "    plt.close()\n",
    "\n",
    "# ------------------ 6) 샘플↔자기 centroid 거리 분포 ------------------\n",
    "# (1 - cosine(sample, class_centroid)) 히스토그램 + 박스\n",
    "for c in classes:\n",
    "    Xi = X[labels == c]\n",
    "    ci = centroids[classes.index(c)].reshape(1,-1)\n",
    "    d = 1 - cosine_similarity(Xi, ci).ravel()\n",
    "    # 히스토그램\n",
    "    plt.figure(figsize=(6,4))\n",
    "    plt.hist(d, bins=30)\n",
    "    plt.title(f\"Distance to Own Centroid (1 - cosine): {c}\")\n",
    "    plt.xlabel(\"1 - cosine\")\n",
    "    plt.ylabel(\"count\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(OUTPUT_DIR, f\"dist_to_centroid_hist_{c.replace(' ','_')}.png\"), dpi=150)\n",
    "    plt.close()\n",
    "    # 박스플롯\n",
    "    plt.figure(figsize=(4,5))\n",
    "    plt.boxplot(d, vert=True, labels=[c])\n",
    "    plt.ylabel(\"1 - cosine\")\n",
    "    plt.title(f\"Box: Dist to Own Centroid\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(OUTPUT_DIR, f\"dist_to_centroid_box_{c.replace(' ','_')}.png\"), dpi=150)\n",
    "    plt.close()\n",
    "\n",
    "# ------------------ 7) Silhouette (cosine) 분포 ------------------\n",
    "le = LabelEncoder(); y = le.fit_transform(labels)\n",
    "sil = silhouette_score(X, y, metric=\"cosine\")\n",
    "print(\"Silhouette (cosine):\", round(sil, 3))\n",
    "s_each = silhouette_samples(X, y, metric=\"cosine\")\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.hist(s_each, bins=30)\n",
    "plt.title(\"Silhouette Score Distribution (cosine)\")\n",
    "plt.xlabel(\"silhouette score\")\n",
    "plt.ylabel(\"count\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUTPUT_DIR, \"silhouette_hist.png\"), dpi=150)\n",
    "plt.close()\n",
    "\n",
    "# ------------------ 8) 2D 임베딩 산점도 (TruncatedSVD) ------------------\n",
    "svd = TruncatedSVD(n_components=2, random_state=42)\n",
    "X2 = svd.fit_transform(X)\n",
    "print(\"SVD explained variance ratio (2D sum):\", svd.explained_variance_ratio_.sum().round(3))\n",
    "\n",
    "plt.figure(figsize=(6,5))\n",
    "for c in classes:\n",
    "    m = (labels == c)\n",
    "    plt.scatter(X2[m,0], X2[m,1], s=18, alpha=0.85, label=c)\n",
    "plt.legend(loc=\"best\", fontsize=8)\n",
    "plt.title(\"TruncatedSVD (TF-IDF word+char, 2D)\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUTPUT_DIR, \"svd_tfidf_scatter.png\"), dpi=150)\n",
    "plt.close()\n",
    "\n",
    "# ------------------ 9) Centroid 덴드로그램 ------------------\n",
    "# 코사인 거리 = 1 - 코사인 유사도\n",
    "D = 1 - centroid_cos_df.values\n",
    "np.fill_diagonal(D, 0.0)\n",
    "condensed = squareform(D, checks=False)\n",
    "Z = linkage(condensed, method=\"average\")\n",
    "plt.figure(figsize=(6,4))\n",
    "dendrogram(Z, labels=classes, orientation=\"top\")\n",
    "plt.title(\"Dendrogram of Class Centroids (cosine distance)\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUTPUT_DIR, \"centroid_dendrogram.png\"), dpi=150)\n",
    "plt.close()\n",
    "\n",
    "# ------------------ 10) (옵션) 샘플링 pairwise cosine 히트맵 ------------------\n",
    "S_PER_CLS = 25  # 클래스당 최대 샘플 수\n",
    "idx_all = []\n",
    "for c in classes:\n",
    "    ids = np.where(labels == c)[0].tolist()\n",
    "    np.random.shuffle(ids)\n",
    "    idx_all.extend(ids[:S_PER_CLS])\n",
    "X_samp = X[idx_all]; labs_samp = labels[idx_all]\n",
    "S = cosine_similarity(X_samp)\n",
    "\n",
    "plt.figure(figsize=(7,6))\n",
    "im = plt.imshow(S, interpolation=\"nearest\")\n",
    "plt.colorbar(im, fraction=0.046, pad=0.04)\n",
    "ticks = range(len(idx_all))\n",
    "plt.xticks(ticks, labs_samp, rotation=90)\n",
    "plt.yticks(ticks, labs_samp)\n",
    "plt.title(f\"Pairwise Cosine (sampled up to {S_PER_CLS}/class)\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUTPUT_DIR, \"pairwise_cosine_sampled_heatmap.png\"), dpi=150)\n",
    "plt.close()\n",
    "\n",
    "# ------------------ 11) 간단 분류 성능(참고) ------------------\n",
    "X_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "clf = LogisticRegression(max_iter=2000, solver=\"liblinear\", multi_class=\"ovr\")\n",
    "clf.fit(X_tr, y_tr)\n",
    "from sklearn.metrics import classification_report\n",
    "print(\"\\n=== Logistic Regression (OVR) on TF-IDF ===\")\n",
    "print(classification_report(y_te, clf.predict(X_te), target_names=classes))\n",
    "\n",
    "print(f\"\\n완료! 결과 이미지/CSV는 '{OUTPUT_DIR}/' 폴더에 저장되었습니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fa2b51cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 클래스별 샘플 수 ===\n",
      "predicate\n",
      "activity notifications    499\n",
      "confirmshaming            298\n",
      "pressured selling         140\n",
      "trick questions            62\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "Embedding with SBERT: sentence-transformers/all-MiniLM-L6-v2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a4739030032499ca06456526742c007",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7856ee4c2345431b88398e081e80e83e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3550001ffd194daaaa1b73af5904c7e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b48597c8d5f4eadb5e1e193bd6ea25b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32c05dd02a7741759dc2d614c7fb1eeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f0249443ccd41f1a639c43415a31094",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fef30d4fd1c435b8f1858242352597e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "903c0533ba60495780e09f2a7174d7bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23d461576261478ba3b008b8b8464cd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ef9c2e56fe64e30b5c4d48e47064faa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fb915244fe64311bdffa2dada229dfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69453769e93f4aeca3a19a002efccae4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== (요약) SBERT 기반 centroid 코사인 유사도 ===\n",
      "                        activity notifications  confirmshaming  \\\n",
      "activity notifications                   1.000           0.312   \n",
      "confirmshaming                           0.312           1.000   \n",
      "pressured selling                        0.586           0.591   \n",
      "trick questions                          0.497           0.552   \n",
      "\n",
      "                        pressured selling  trick questions  \n",
      "activity notifications              0.586            0.497  \n",
      "confirmshaming                      0.591            0.552  \n",
      "pressured selling                   1.000            0.836  \n",
      "trick questions                     0.836            1.000   \n",
      "\n",
      "Silhouette (cosine): 0.15 (~0.2↑ 꽤 분리, 0.4↑ 매우 잘 분리)\n",
      "\n",
      "UMAP 사용 불가(fallback to TruncatedSVD): Numba needs NumPy 2.2 or less. Got NumPy 2.3.\n",
      "SVD 2D 산점도 생성 완료.\n",
      "완료! 결과는 'sb_out/' 폴더에 저장되었습니다.\n",
      "- centroid_cosine.csv / centroid_*_heatmap.png / centroid_cosine_distance.csv\n",
      "- intra_cosine_hist_*.png / inter_cosine_hist_*__*.png\n",
      "- silhouette_hist.png\n",
      "- umap_scatter.png (또는 svd_scatter.png)\n",
      "- pairwise_cosine_sampled_heatmap.png\n",
      "- representative_examples.txt\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# SBERT 기반 4개 predicate 유사도/분포 분석 (올인원)\n",
    "# 대상: confirmshaming / trick questions / pressured selling / activity notifications\n",
    "# - SBERT 임베딩(all-MiniLM-L6-v2, 384D, fast)\n",
    "# - Centroid 코사인 유사도/거리, Intra/Inter 코사인 분포\n",
    "# - Silhouette(코사인) 지표, 2D 임베딩(UMAP→SVD fallback)\n",
    "# - 대표 문장(centroid 근접 Top-K) 추출\n",
    "# - 샘플링 pairwise cosine 히트맵\n",
    "# 산출물: sb_out/ 폴더에 PNG/CSV/TXT 저장\n",
    "# ============================================\n",
    "\n",
    "import os, re, numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import silhouette_score, silhouette_samples\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "# ---------- 경로/모델 설정 ----------\n",
    "FILE_PATH = \"/Users/soyoung/404DNF_AI/data/processed/template_predicate.csv\"   # 필요 시 절대경로로 변경: /mnt/data/paraphrase_predicate.csv\n",
    "OUTPUT_DIR = \"sb_out\"; os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "TARGET_PREDICATES = [\n",
    "    \"confirmshaming\",\n",
    "    \"trick questions\",\n",
    "    \"pressured selling\",\n",
    "    \"activity notifications\",\n",
    "]\n",
    "\n",
    "MODEL_NAME = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "# 다국어 문장 섞여 있으면:\n",
    "# MODEL_NAME = \"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\"\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "TOPK_REPR = 20\n",
    "SAMPLE_PER_CLASS_FOR_HEATMAP = 25\n",
    "\n",
    "# ---------- 1) 데이터 로드/필터 ----------\n",
    "df = pd.read_csv(FILE_PATH)\n",
    "assert {\"String\",\"predicate\"} <= set(df.columns), \"CSV에 String, predicate 컬럼이 필요합니다.\"\n",
    "df = df.dropna(subset=[\"String\",\"predicate\"]).copy()\n",
    "df[\"predicate\"] = df[\"predicate\"].str.lower().str.strip()\n",
    "\n",
    "mask = df[\"predicate\"].isin([p.lower() for p in TARGET_PREDICATES])\n",
    "data = df.loc[mask].reset_index(drop=True)\n",
    "if data.empty:\n",
    "    raise ValueError(\"선택한 predicate가 데이터에 없습니다.\")\n",
    "\n",
    "print(\"=== 클래스별 샘플 수 ===\")\n",
    "print(data[\"predicate\"].value_counts(), \"\\n\")\n",
    "\n",
    "texts = data[\"String\"].astype(str).tolist()\n",
    "labels = data[\"predicate\"].values\n",
    "classes = sorted(pd.unique(labels))\n",
    "\n",
    "# ---------- 2) SBERT 임베딩 ----------\n",
    "print(\"Embedding with SBERT:\", MODEL_NAME)\n",
    "model = SentenceTransformer(MODEL_NAME)\n",
    "emb = model.encode(\n",
    "    texts,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    normalize_embeddings=True,   # L2 정규화 -> 코사인 = 내적\n",
    "    convert_to_numpy=True,\n",
    "    show_progress_bar=True\n",
    ")  # shape: [N, D], 각 벡터는 단위 벡터\n",
    "\n",
    "# ---------- 3) 클래스 centroid 및 유사도 ----------\n",
    "centroids = []\n",
    "for c in classes:\n",
    "    ci = emb[labels == c].mean(axis=0)\n",
    "    # 평균 후 다시 정규화 (단위 벡터로)\n",
    "    norm = np.linalg.norm(ci) + 1e-12\n",
    "    centroids.append(ci / norm)\n",
    "centroids = np.vstack(centroids)  # [C, D]\n",
    "\n",
    "# centroid 코사인/거리\n",
    "centroid_cos = centroids @ centroids.T  # 단위벡터 -> 코사인 = 내적\n",
    "centroid_dist = 1 - centroid_cos\n",
    "\n",
    "centroid_cos_df = pd.DataFrame(centroid_cos, index=classes, columns=classes)\n",
    "centroid_cos_df.to_csv(os.path.join(OUTPUT_DIR, \"centroid_cosine.csv\"))\n",
    "pd.DataFrame(centroid_dist, index=classes, columns=classes).to_csv(\n",
    "    os.path.join(OUTPUT_DIR, \"centroid_cosine_distance.csv\")\n",
    ")\n",
    "\n",
    "def heatmap(mat, ticks, title, path):\n",
    "    plt.figure(figsize=(6,5))\n",
    "    im = plt.imshow(mat, interpolation=\"nearest\")\n",
    "    plt.colorbar(im, fraction=0.046, pad=0.04)\n",
    "    plt.xticks(range(len(ticks)), ticks, rotation=45, ha=\"right\")\n",
    "    plt.yticks(range(len(ticks)), ticks)\n",
    "    plt.title(title)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(path, dpi=150); plt.close()\n",
    "\n",
    "heatmap(centroid_cos, classes, \"Centroid Cosine Similarity (SBERT)\", os.path.join(OUTPUT_DIR, \"centroid_cosine_heatmap.png\"))\n",
    "heatmap(centroid_dist, classes, \"Centroid Cosine Distance (1-cos)\", os.path.join(OUTPUT_DIR, \"centroid_distance_heatmap.png\"))\n",
    "\n",
    "print(\"=== (요약) SBERT 기반 centroid 코사인 유사도 ===\")\n",
    "print(centroid_cos_df.round(3), \"\\n\")\n",
    "\n",
    "# ---------- 4) Intra/Inter 코사인 분포 ----------\n",
    "# Intra: 같은 클래스 내 문장-문장 코사인 분포 (히스토그램)\n",
    "for c in classes:\n",
    "    idx = np.where(labels == c)[0]\n",
    "    if len(idx) < 2: \n",
    "        continue\n",
    "    S = cosine_similarity(emb[idx])\n",
    "    iu = np.triu_indices_from(S, k=1)\n",
    "    vals = S[iu]\n",
    "    plt.figure(figsize=(6,4))\n",
    "    plt.hist(vals, bins=30)\n",
    "    plt.title(f\"Intra-class Cosine (SBERT): {c}\")\n",
    "    plt.xlabel(\"cosine\"); plt.ylabel(\"count\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(OUTPUT_DIR, f\"intra_cosine_hist_{c.replace(' ','_')}.png\"), dpi=150)\n",
    "    plt.close()\n",
    "\n",
    "# Inter: 서로 다른 클래스 간 문장-문장 코사인 분포 (히스토그램)\n",
    "import itertools\n",
    "for a, b in itertools.combinations(classes, 2):\n",
    "    Sa = emb[labels == a]; Sb = emb[labels == b]\n",
    "    sims = cosine_similarity(Sa, Sb).ravel()\n",
    "    plt.figure(figsize=(6,4))\n",
    "    plt.hist(sims, bins=30)\n",
    "    plt.title(f\"Inter-class Cosine (SBERT): {a} vs {b}\")\n",
    "    plt.xlabel(\"cosine\"); plt.ylabel(\"count\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(OUTPUT_DIR, f\"inter_cosine_hist_{a.replace(' ','_')}__{b.replace(' ','_')}.png\"), dpi=150)\n",
    "    plt.close()\n",
    "\n",
    "# ---------- 5) Silhouette (cosine) 전반 분리도 ----------\n",
    "le = LabelEncoder(); y = le.fit_transform(labels)\n",
    "sil = silhouette_score(emb, y, metric=\"cosine\")\n",
    "print(\"Silhouette (cosine):\", round(sil, 3), \"(~0.2↑ 꽤 분리, 0.4↑ 매우 잘 분리)\\n\")\n",
    "\n",
    "# 분포 그림\n",
    "s_each = silhouette_samples(emb, y, metric=\"cosine\")\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.hist(s_each, bins=30)\n",
    "plt.title(\"Silhouette Score Distribution (cosine, SBERT)\")\n",
    "plt.xlabel(\"silhouette score\"); plt.ylabel(\"count\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUTPUT_DIR, \"silhouette_hist.png\"), dpi=150)\n",
    "plt.close()\n",
    "\n",
    "# ---------- 6) 2D 임베딩 산점도 (UMAP → SVD fallback) ----------\n",
    "def scatter_2d(X2, labels_str, title, path):\n",
    "    plt.figure(figsize=(6,5))\n",
    "    for c in classes:\n",
    "        m = (labels_str == c)\n",
    "        plt.scatter(X2[m,0], X2[m,1], s=18, alpha=0.85, label=c)\n",
    "    plt.legend(loc=\"best\", fontsize=8)\n",
    "    plt.title(title)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(path, dpi=150); plt.close()\n",
    "\n",
    "try:\n",
    "    import umap\n",
    "    reducer = umap.UMAP(n_components=2, random_state=42, metric=\"cosine\")\n",
    "    X2 = reducer.fit_transform(emb)\n",
    "    scatter_2d(X2, labels, \"UMAP (SBERT, cosine)\", os.path.join(OUTPUT_DIR, \"umap_scatter.png\"))\n",
    "    print(\"UMAP 2D 산점도 생성 완료.\")\n",
    "except Exception as e:\n",
    "    print(\"UMAP 사용 불가(fallback to TruncatedSVD):\", e)\n",
    "    svd = TruncatedSVD(n_components=2, random_state=42)\n",
    "    X2 = svd.fit_transform(emb)  # 단위벡터지만 SVD로 투영\n",
    "    scatter_2d(X2, labels, \"TruncatedSVD (SBERT)\", os.path.join(OUTPUT_DIR, \"svd_scatter.png\"))\n",
    "    print(\"SVD 2D 산점도 생성 완료.\")\n",
    "\n",
    "# ---------- 7) 샘플링 pairwise cosine 히트맵 ----------\n",
    "np.random.seed(42)\n",
    "idx_all = []\n",
    "for c in classes:\n",
    "    ids = np.where(labels == c)[0].tolist()\n",
    "    np.random.shuffle(ids)\n",
    "    idx_all.extend(ids[:SAMPLE_PER_CLASS_FOR_HEATMAP])\n",
    "emb_s = emb[idx_all]; labs_s = labels[idx_all]\n",
    "S = cosine_similarity(emb_s)\n",
    "\n",
    "plt.figure(figsize=(7,6))\n",
    "im = plt.imshow(S, interpolation=\"nearest\")\n",
    "plt.colorbar(im, fraction=0.046, pad=0.04)\n",
    "ticks = range(len(idx_all))\n",
    "plt.xticks(ticks, labs_s, rotation=90)\n",
    "plt.yticks(ticks, labs_s)\n",
    "plt.title(f\"Pairwise Cosine (SBERT, sampled up to {SAMPLE_PER_CLASS_FOR_HEATMAP}/class)\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUTPUT_DIR, \"pairwise_cosine_sampled_heatmap.png\"), dpi=150)\n",
    "plt.close()\n",
    "\n",
    "# ---------- 8) 클래스별 대표 문장(centroid 근접 Top-K) ----------\n",
    "with open(os.path.join(OUTPUT_DIR, \"representative_examples.txt\"), \"w\", encoding=\"utf-8\") as f:\n",
    "    for i, c in enumerate(classes):\n",
    "        sim_to_c = emb[labels==c] @ centroids[i]  # 단위벡터 내적 = 코사인\n",
    "        idx_local = np.argsort(-sim_to_c)[:TOPK_REPR]\n",
    "        ex_texts = data.loc[labels==c, \"String\"].iloc[idx_local].tolist()\n",
    "        f.write(f\"[{c}] centroid-near examples (Top {TOPK_REPR})\\n\")\n",
    "        for t in ex_texts:\n",
    "            f.write(\"- \" + str(t).replace(\"\\n\",\" \") + \"\\n\")\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "print(f\"완료! 결과는 '{OUTPUT_DIR}/' 폴더에 저장되었습니다.\")\n",
    "print(\"- centroid_cosine.csv / centroid_*_heatmap.png / centroid_cosine_distance.csv\")\n",
    "print(\"- intra_cosine_hist_*.png / inter_cosine_hist_*__*.png\")\n",
    "print(\"- silhouette_hist.png\")\n",
    "print(\"- umap_scatter.png (또는 svd_scatter.png)\")\n",
    "print(\"- pairwise_cosine_sampled_heatmap.png\")\n",
    "print(\"- representative_examples.txt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b3c305",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
