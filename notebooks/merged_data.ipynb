{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c943594",
   "metadata": {},
   "source": [
    "### 1. dark-patterns.csv 에서 string, type, predicate만 뽑아서 저장\n",
    "\n",
    "- 중복 제거 시 완전히 동일한 문장만 제거\n",
    "    - 공백/대소문자 차이까지는 묶지 않음\n",
    "\n",
    "- 저장 csv 이름 : predicate_GT.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0ec530",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type\n",
      "Scarcity        679\n",
      "Urgency         481\n",
      "Social Proof    325\n",
      "Misdirection    270\n",
      "Name: count, dtype: int64\n",
      "Removed per Type:\n",
      " Type\n",
      "Misdirection     74\n",
      "Scarcity        259\n",
      "Social Proof     12\n",
      "Urgency         270\n",
      "Name: String, dtype: int64\n",
      "Type\n",
      "Scarcity        420\n",
      "Social Proof    313\n",
      "Urgency         211\n",
      "Misdirection    196\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "CSV_PATH = \"/Users/soyoung/404DNF_AI/data/raw/dark-patterns.csv\"  # 필요시 경로 수정\n",
    "\n",
    "# 1) 읽기 + 필요한 컬럼만\n",
    "df = pd.read_csv(CSV_PATH)[['Pattern String', 'Pattern Category', 'Pattern Type']].copy()\n",
    "df['String'] = df['Pattern String'].astype(str).str.strip()\n",
    "\n",
    "# 2) Pattern Category 정규화 후 우리가 원하는 4종만 남기기\n",
    "WANTED = {\"Urgency\", \"Misdirection\", \"Social Proof\", \"Scarcity\"}\n",
    "ALIASES = {\n",
    "    \"urgency\": \"Urgency\",\n",
    "    \"misdirection\": \"Misdirection\",\n",
    "    \"scarcity\": \"Scarcity\",\n",
    "    \"socialproof\": \"Social Proof\",\n",
    "    \"social-proof\": \"Social Proof\",\n",
    "    \"social proof\": \"Social Proof\",\n",
    "}\n",
    "\n",
    "def normalize_category(x):\n",
    "    if pd.isna(x): \n",
    "        return None\n",
    "    s = str(x).strip().lower()\n",
    "    s = re.sub(r\"\\s+\", \" \", s)  # 여러 공백 정리\n",
    "    s = s.replace(\"-\", \" - \").replace(\"  \", \" \").replace(\" - \", \"-\")  # 하이픈 주변 공백 정리\n",
    "    if s in ALIASES:\n",
    "        out = ALIASES[s]\n",
    "    else:\n",
    "        out = \" \".join(w.capitalize() for w in s.split())\n",
    "    return out if out in WANTED else None\n",
    "\n",
    "df['_TypeNorm'] = df['Pattern Category'].map(normalize_category)\n",
    "df = df[df['_TypeNorm'].notna()].copy()\n",
    "\n",
    "# 3) 컬럼명/값 맞추기: Type은 정규화된 값으로, Predicate은 원래 'Pattern Type'\n",
    "predicate_gt = (\n",
    "    df.assign(Type=df['_TypeNorm'])\n",
    "      .rename(columns={'Pattern Type': 'Predicate'})\n",
    "      [['String', 'Type', 'Predicate']]\n",
    "      .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# 중복 제거 전\n",
    "# print(predicate_gt.head())\n",
    "print(predicate_gt['Type'].value_counts())\n",
    "\n",
    "# Type + String 기준으로 완전 동일한 중복 제거\n",
    "predicate_gt_dedup = (\n",
    "    predicate_gt\n",
    "    .drop_duplicates(subset=['Type', 'String'])\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# (선택) 얼마나 줄었는지 확인\n",
    "removed_by_type = (\n",
    "    predicate_gt.groupby('Type')['String'].size()\n",
    "    - predicate_gt_dedup.groupby('Type')['String'].size()\n",
    ")\n",
    "\n",
    "# 줄어든 개수 확인\n",
    "print(\"Removed per Type:\\n\", removed_by_type.fillna(0).astype(int))\n",
    "# 중복 제거 후 각 type별 개수 확인\n",
    "print(predicate_gt_dedup['Type'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "70fc39a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /Users/soyoung/404DNF_AI/data/raw/predicate_GT.csv\n",
      "(1140, 3)\n",
      "Type\n",
      "Scarcity        420\n",
      "Social Proof    313\n",
      "Urgency         211\n",
      "Misdirection    196\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# 입력 CSV가 있는 폴더(data/raw)로 저장 경로 지정\n",
    "out_dir = Path(CSV_PATH).parent\n",
    "out_path = out_dir / \"predicate_GT.csv\"\n",
    "\n",
    "# 정렬(옵션) 후 저장\n",
    "predicate_gt_dedup.sort_values(['Type', 'String']).to_csv(\n",
    "    out_path, index=False, encoding=\"utf-8-sig\"\n",
    ")\n",
    "\n",
    "print(f\"Saved: {out_path}\")\n",
    "print(predicate_gt_dedup.shape)\n",
    "print(predicate_gt_dedup['Type'].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbcaa308",
   "metadata": {},
   "source": [
    "### 2. datset.tsv에서 중복제거 하고 binary label만 두기\n",
    "\n",
    "- 중복 제거 시 완전히 동일한 문장만 제거\n",
    "    - 대소문자, 공백은 고려하지 않음\n",
    "\n",
    "- 저장 csv 이름 : binary_label.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d03ad82c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label counts (before / after / removed):\n",
      "       before  after  removed\n",
      "label                        \n",
      "0        1178   1178        0\n",
      "1        1178   1178        0\n",
      "\n",
      "Totals: before=2356 after=2356 removed=0\n",
      "\n",
      "Saved: /Users/soyoung/404DNF_AI/data/raw/binary_label.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# ===== 1) 입력 경로 =====\n",
    "SRC_PATH = Path(\"/Users/soyoung/404DNF_AI/data/raw/dataset.tsv\")\n",
    "sep = \"\\t\" if SRC_PATH.suffix.lower() in {\".tsv\", \".tab\"} else \",\"\n",
    "\n",
    "# ===== 2) 읽기 =====\n",
    "df = pd.read_csv(SRC_PATH, sep=sep)\n",
    "\n",
    "# ===== 3) (text, label) 컬럼 사용 =====\n",
    "if not {\"text\", \"label\"}.issubset(df.columns):\n",
    "    raise KeyError(f\"'text', 'label' 컬럼이 필요합니다. 현재 컬럼: {list(df.columns)}\")\n",
    "\n",
    "binary_df = df[[\"text\", \"label\"]].copy()\n",
    "\n",
    "# ===== 4) 중복 제거 전 라벨 분포 =====\n",
    "before_counts = binary_df[\"label\"].value_counts().sort_index()\n",
    "\n",
    "# ===== 5) 문장(text) 기준 완전 동일 중복 제거 =====\n",
    "dup_mask = binary_df.duplicated(subset=[\"text\"], keep=\"first\")\n",
    "removed_df = binary_df[dup_mask]                 # 제거될 행들\n",
    "after_df   = binary_df[~dup_mask].reset_index(drop=True)\n",
    "\n",
    "# ===== 6) 중복 제거 후 라벨 분포 =====\n",
    "after_counts = after_df[\"label\"].value_counts().sort_index()\n",
    "removed_counts = removed_df[\"label\"].value_counts().sort_index()\n",
    "\n",
    "# ===== 7) 요약 출력 =====\n",
    "labels = sorted(set(before_counts.index) | set(after_counts.index) | set(removed_counts.index))\n",
    "summary = pd.DataFrame({\n",
    "    \"before\": before_counts.reindex(labels, fill_value=0),\n",
    "    \"after\":  after_counts.reindex(labels, fill_value=0),\n",
    "    \"removed\": removed_counts.reindex(labels, fill_value=0),\n",
    "}).astype(int)\n",
    "\n",
    "print(\"Label counts (before / after / removed):\")\n",
    "print(summary)\n",
    "print(\"\\nTotals:\",\n",
    "      f\"before={len(binary_df)}\",\n",
    "      f\"after={len(after_df)}\",\n",
    "      f\"removed={len(removed_df)}\")\n",
    "\n",
    "# ===== 8) 저장: 원본과 같은 폴더에 binary_label.csv =====\n",
    "out_path = SRC_PATH.parent / \"binary_label.csv\"\n",
    "after_df.to_csv(out_path, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "print(f\"\\nSaved: {out_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f33cdd",
   "metadata": {},
   "source": [
    "### 3. dataset.tsv, dark-patterns.csv merge\n",
    "\n",
    "- Not Dark Pattern, Urgency, Misdirection, Scarcity, Social Proof 5가지 type만 저장\n",
    "    - 중복 제거 시 완전히 동일한 문장만 제거, 띄어쓰기/대소문자에 대해서는 신경 쓰지 않음\n",
    "\n",
    "- 저장 csv 이름 : merged.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4fcfc9f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /Users/soyoung/404DNF_AI/data/raw/merged.csv\n",
      "Shape: (3453, 2)\n",
      "Type distribution:\n",
      " Type\n",
      "Not Dark Pattern    1178\n",
      "Scarcity             838\n",
      "Social Proof         625\n",
      "Urgency              421\n",
      "Misdirection         391\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "# ===== 0) 경로 =====\n",
    "SRC_TSV = Path(\"/Users/soyoung/404DNF_AI/data/raw/dataset.tsv\")        # .tsv 원본\n",
    "SRC_GT  = Path(\"/Users/soyoung/404DNF_AI/data/raw/predicate_GT.csv\")   # predicate_GT.csv\n",
    "sep_tsv = \"\\t\" if SRC_TSV.suffix.lower() in {\".tsv\", \".tab\"} else \",\"\n",
    "\n",
    "# ===== 1) 공통: Type 정규화(대소문자/공백/하이픈) + 5개만 허용 =====\n",
    "WANTED = {\"Not Dark Pattern\", \"Urgency\", \"Misdirection\", \"Scarcity\", \"Social Proof\"}\n",
    "ALIASES = {\n",
    "    # Not Dark Pattern\n",
    "    \"notdarkpattern\": \"Not Dark Pattern\",\n",
    "    \"not-dark-pattern\": \"Not Dark Pattern\",\n",
    "    \"not dark pattern\": \"Not Dark Pattern\",\n",
    "    \"no dark pattern\": \"Not Dark Pattern\",\n",
    "    \"non dark pattern\": \"Not Dark Pattern\",\n",
    "    # Others\n",
    "    \"urgency\": \"Urgency\",\n",
    "    \"misdirection\": \"Misdirection\",\n",
    "    \"scarcity\": \"Scarcity\",\n",
    "    \"socialproof\": \"Social Proof\",\n",
    "    \"social-proof\": \"Social Proof\",\n",
    "    \"social proof\": \"Social Proof\",\n",
    "}\n",
    "\n",
    "def normalize_type(x):\n",
    "    if pd.isna(x):\n",
    "        return None\n",
    "    s = str(x).strip().lower()\n",
    "    s = re.sub(r\"\\s+\", \" \", s)  # 여러 공백 → 한 칸\n",
    "    # 하이픈 주변 불규칙 공백 정리\n",
    "    s = s.replace(\"-\", \" - \").replace(\"  \", \" \").replace(\" - \", \"-\")\n",
    "    if s in ALIASES:\n",
    "        out = ALIASES[s]\n",
    "    else:\n",
    "        out = \" \".join(w.capitalize() for w in s.split())\n",
    "    return out if out in WANTED else None\n",
    "\n",
    "# ===== 2) .tsv 정제: page_id 제거, text→String, Pattern Category→Type, 5개만 사용 =====\n",
    "df_tsv = pd.read_csv(SRC_TSV, sep=sep_tsv)\n",
    "\n",
    "# String 만들기 (text 우선, 없으면 예비 컬럼 시도)\n",
    "if \"text\" in df_tsv.columns:\n",
    "    string_series = df_tsv[\"text\"].astype(str).str.strip()\n",
    "elif \"Pattern String\" in df_tsv.columns:\n",
    "    string_series = df_tsv[\"Pattern String\"].astype(str).str.strip()\n",
    "elif \"String\" in df_tsv.columns:\n",
    "    string_series = df_tsv[\"String\"].astype(str).str.strip()\n",
    "else:\n",
    "    raise KeyError(f\"문장 컬럼을 찾지 못했습니다. 현재 컬럼: {list(df_tsv.columns)}\")\n",
    "\n",
    "# Type 만들기 (Pattern Category 우선, 없으면 label로 대체)\n",
    "if \"Pattern Category\" in df_tsv.columns:\n",
    "    type_series = df_tsv[\"Pattern Category\"].map(normalize_type)\n",
    "elif \"label\" in df_tsv.columns:\n",
    "    type_series = df_tsv[\"label\"].map(normalize_type)\n",
    "else:\n",
    "    raise KeyError(\"Type 정보를 만들 컬럼이 없습니다. ('Pattern Category' 또는 'label' 필요)\")\n",
    "\n",
    "df_tsv_out = pd.DataFrame({\"String\": string_series, \"Type\": type_series})\n",
    "df_tsv_out = df_tsv_out[df_tsv_out[\"Type\"].notna()].reset_index(drop=True)  # 5개만 남기기\n",
    "\n",
    "# (참고) page_id는 최종 컬럼에 포함하지 않으므로 자연스럽게 제거됨\n",
    "\n",
    "# ===== 3) predicate_GT.csv 정제: String, Type만 사용 + Type 재정규화로 5개만 유지 =====\n",
    "df_gt = pd.read_csv(SRC_GT)\n",
    "\n",
    "# 컬럼 이름 보정(혹시 'Pattern String', 'Pattern Category'로 되어 있다면)\n",
    "if not {\"String\", \"Type\"}.issubset(df_gt.columns):\n",
    "    df_gt = df_gt.rename(columns={\n",
    "        \"Pattern String\": \"String\",\n",
    "        \"Pattern Category\": \"Type\",\n",
    "    })\n",
    "\n",
    "if not {\"String\", \"Type\"}.issubset(df_gt.columns):\n",
    "    raise KeyError(f\"predicate_GT.csv에서 'String','Type' 컬럼을 찾지 못했습니다. 현재 컬럼: {list(df_gt.columns)}\")\n",
    "\n",
    "df_gt_out = df_gt[[\"String\", \"Type\"]].copy()\n",
    "df_gt_out[\"String\"] = df_gt_out[\"String\"].astype(str).str.strip()\n",
    "df_gt_out[\"Type\"]   = df_gt_out[\"Type\"].map(normalize_type)\n",
    "df_gt_out = df_gt_out[df_gt_out[\"Type\"].notna()].reset_index(drop=True)   # 5개만 유지\n",
    "\n",
    "# ===== 4) 머지(세로 결합) + 저장 =====\n",
    "merged = pd.concat([df_tsv_out, df_gt_out], ignore_index=True)\n",
    "\n",
    "out_path = SRC_TSV.parent / \"merged.csv\"   # .tsv와 같은 폴더에 저장\n",
    "merged.to_csv(out_path, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "print(f\"Saved: {out_path}\")\n",
    "print(\"Shape:\", merged.shape)\n",
    "print(\"Type distribution:\\n\", merged[\"Type\"].value_counts())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
